{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **THE CHURN FACTOR: UNLOCKING CUSTOMER ROYALTY IN TELECOM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BUSINESS UNDERSTANDING**\n",
    "\n",
    "Understanding telecom customer churn is crucial for businesses in the telecommunications industry, as it directly impacts revenue, customer retention, and overall profitability. Customer churn can be voluntary because of dissatisfaction in the services by the service provider and it can also be involuntary because of service disruption or payment issues. Understanding customer churn rates can have financial implications to the provider. Maintaining current customers is cheaper than that acquiring new ones. Analysing churn rates can give an advantage over competitors. This project aims to predict whether a customer will churn or not depending on the several factors on the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA UNDERSTANDING\n",
    "This SyriaTel data is from https://www.kaggle.com/datasets/becksddf/churn-in-telecoms-dataset, a Telecommunication company.\n",
    "The dataset contains information about customer churn, which is a significant problem for telecom companies. The goal is\n",
    "to predict whether a customer will churn or not.\n",
    "The dataset contains the following columns:'state', 'account length', 'area code', 'phone number','international plan', 'voice mail plan', 'number vmail messages','total day minutes', 'total day calls', 'total day charge','total eve minutes', 'total eve calls', 'total eve charge','total night minutes', 'total night calls', 'total night charge','total intl minutes', 'total intl calls', 'total intl charge','customer service calls', 'churn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, f1_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\hp\\Documents\\telecom-project\\data\\bigml_59c28831336c6604c800002a.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigating the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigating the statistical features of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates in the dataset\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset does not have any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataset there are no missing values, so we go ahead and analyse the data through eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BAR PLOT: CUSTOMER CHURN RATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating churn rates\n",
    "churn_rate = df['churn'].mean() * 100\n",
    "\n",
    "#plotting a barplot\n",
    "sns.countplot(x='churn', data=df, palette=['blue', 'pink'])\n",
    "plt.title('Churn Distribution')\n",
    "plt.xlabel('Churn Status')\n",
    "plt.ylabel('Count')\n",
    "plt.text(1, 0.5, f\"Churn Rate: {churn_rate:.2f}%\",\n",
    "         transform=plt.gca().transAxes,\n",
    "         horizontalalignment='right',\n",
    "         verticalalignment='center',\n",
    "         fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot indicates a churn rate of 14.49%. This means that approximately 14.49% of customers have left or are likely to leave the company.The majority of customers (represented by the blue bar) have not churned (False). The smaller pink bar represents the portion of customers who have churned (True).\n",
    "Customer Retention: The company has a relatively high proportion of customers who have remained loyal.\n",
    "Churn Prevention: Despite the majority of customers staying, the churn rate of 14.49% suggests that there is room for improvement in customer retention efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COUNTPLOTS FOR CATEGORICAL COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying categorical columns\n",
    "categorical_cols = ['state', 'area code', 'international plan', 'voice mail plan', 'phone number']\n",
    "\n",
    "#plotting the count plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8)) \n",
    "\n",
    "#iterating through the categorical columns\n",
    "col_idx = 0\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        if col_idx >= len(categorical_cols):\n",
    "            break\n",
    "\n",
    "        col_name = categorical_cols[col_idx]\n",
    "        sns.countplot(x=col_name, hue='churn', data=df, ax=axes[row, col])\n",
    "        axes[row, col].set_title(f'{col_name} vs. Churn')\n",
    "        axes[row, col].set_xlabel(col_name)\n",
    "        axes[row, col].set_ylabel('Count')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        col_idx += 1\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State: The plot shows that the number of churned customers is relatively consistent across different states, with a few states having slightly higher or lower churn rates.\n",
    "Area Code: While the area code 415 has the highest number of customers, the churn rates across the three area codes (408, 415, and 510) are relatively similar.\n",
    "International Plan: Customers with an international plan have a significantly higher churn rate compared to those without.\n",
    "Voice Mail Plan: Customers with a voice mail plan have a slightly lower churn rate compared to those without.\n",
    "International Plan: The international plan seems to be a strong predictor of churn. The company may want to investigate why customers with international plans are more likely to churn.\n",
    "Voice Mail Plan: While the effect is less pronounced, having a voice mail plan appears to be slightly correlated with lower churn rates.\n",
    "State and Area Code: While there are some variations in churn rates across states and area codes, these factors do not seem to be as significant as the international plan and voice mail plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HISTOGRAM FOR NUMERICAL COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying numerical columns\n",
    "numerical_cols = ['account length', 'total day minutes', 'total day calls',\n",
    "                  'total eve minutes', 'total eve calls', 'total night minutes',\n",
    "                  'total night calls', 'total intl minutes', 'customer service calls']\n",
    "\n",
    "#plotting the histogram\n",
    "sns.set(style='whitegrid')\n",
    "fig, axes = plt.subplots(len(numerical_cols), 1, figsize=(10, 30))\n",
    "fig.suptitle('Distribution of Numerical Features with KDE', fontsize=16)\n",
    "\n",
    "#iterating through each numerical column\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    sns.histplot(df[col], bins=20, kde=True, ax=axes[i], color='skyblue')\n",
    "    axes[i].set_title(f'Distribution of {col}', fontsize=14)\n",
    "    axes[i].set_xlabel('') \n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout(h_pad=1.0, w_pad=1.0) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Account Length: The distribution of account length appears to be right-skewed, with a longer tail on the right side. This indicates that there are some customers who have been with the company for a significantly longer time than the average.\n",
    "Total Minutes (Day, Eve, Night): The distributions of total minutes for day, evening, and night calls are all right-skewed, suggesting that there are some customers who make significantly more calls than the average.\n",
    "Total Calls (Day, Eve, Night): The distributions of total calls for day, evening, and night are also right-skewed, indicating that there are some customers who make a significantly larger number of calls than the average.\n",
    "Total International Minutes: The distribution of total international minutes is right-skewed, with a longer tail on the right side. This suggests that there are some customers who make significantly more international calls than the average.\n",
    "Customer Service Calls: The distribution of customer service calls is right-skewed, with a longer tail on the right side. This indicates that there are some customers who require significantly more customer service assistance than the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PAIRPLOTS BETWEEN FEATURES AND CUSTOMER CHURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplots for relationships between features and churn\n",
    "sns.pairplot(df, hue='churn', vars=numerical_cols)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer Usage Patterns: Many customers have usage patterns that deviate from the average, as evidenced by the skewed distributions.\n",
    "Variable Relationships: Several variables exhibit strong positive or negative correlations, suggesting interconnected relationships.\n",
    "Customer Segmentation: The plots hint at potential customer segments based on distinct usage patterns.\n",
    "Data Anomalies: A few outliers were identified, potentially indicating unusual customer behavior or data errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOX PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for customer service calls vs churn\n",
    "sns.boxplot(\n",
    "    x = \"churn\",\n",
    "    y = \"customer service calls\",\n",
    "    showmeans=True,\n",
    "    data=df\n",
    ")\n",
    "\n",
    "plt.title('Customer Service Calls Distribution by Churn') \n",
    "plt.xlabel('Churn (Yes or No)')\n",
    "plt.ylabel('Customer Service Calls') \n",
    "plt.xticks(rotation=45) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the median number of customer service calls is slightly higher for churned customers, the overall distributions are quite similar. This suggests that the number of customer service calls alone may not be a strong predictor of churn. However, the presence of outliers in both groups indicates that there might be other factors influencing churn, and further analysis is needed to understand the relationship between customer service calls and churn more comprehensively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COUNTPLOT FOR DISTRIBUTION OF CUSTOMER SERVICE CALLS VS CHURN STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the countplot\n",
    "sns.countplot(\n",
    "    x = \"customer service calls\",\n",
    "    hue = \"churn\",\n",
    "    data=df,\n",
    "    palette=\"Set2\"\n",
    ")\n",
    "\n",
    "plt.title('Distribution of Customer Service Calls by Churn Status')  \n",
    "plt.xlabel('Number of Customer Service Calls')  \n",
    "plt.ylabel('Number of Customers')  \n",
    "plt.xticks(rotation=45) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the overall distributions are similar, the data suggests that customers who churned are slightly more likely to have made more customer service calls. However, this relationship is not strong, and other factors may also contribute to churn. It's important to consider the context of your data and explore additional variables to gain a deeper understanding of the relationship between customer service calls and churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COUNTPLOT: INTERNATIONAL PLAN VS CHURN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a count plot\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='international plan', hue='churn', data=df, palette='Set1')\n",
    "plt.title('International Plan vs Churn', fontsize=16)\n",
    "plt.xlabel('International Plan', fontsize=14)\n",
    "plt.ylabel('Customer Count', fontsize=14)\n",
    "plt.legend(title='Churn', loc='upper right', fontsize=12, title_fontsize='13')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot suggests a strong association between having an international plan and customer churn. Customers who subscribed to the international plan are more likely to churn compared to those who did not. This could indicate potential issues or dissatisfaction with the international plan service, which might be worth investigating further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HISTOGRAM OF NEW FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new feature: total minutes\n",
    "df['total minutes'] = df['total day minutes'] + df['total eve minutes'] + df['total night minutes'] + df['total intl minutes']\n",
    "\n",
    "#creating a new feature: total charges\n",
    "df['total charges'] = df['total day charge'] + df['total eve charge'] + df['total night charge'] + df['total intl charge']\n",
    "\n",
    "#plotting the distribution of total minutes\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['total minutes'], bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Total Minutes')\n",
    "\n",
    "# Histogram for total charges\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['total charges'], bins=20, kde=True, color='salmon')\n",
    "plt.title('Distribution of Total Charges')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both histograms show a similar bell-curve shape, suggesting that most customers have usage patterns that are fairly consistent. However, there's slightly more variation in total charges compared to total minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEALING WITH CATEGORICAL COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a copy of the data\n",
    "df2 = df.copy()\n",
    "\n",
    "#creating an instance of OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "\n",
    "#fitting the encoder on the categorical columns and transform the data\n",
    "encoded_features = encoder.fit_transform(df2[categorical_cols])\n",
    "\n",
    "# Create a DataFrame from the encoded features\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Concatenate the encoded data with the remaining columns\n",
    "df2 = pd.concat([df2.drop(categorical_cols, axis=1), encoded_df], axis=1)\n",
    "\n",
    "# Print the modified DataFrame\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciating the standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fitting the standardscaler\n",
    "scaler.fit(df2[numerical_cols])\n",
    "df2[numerical_cols] = scaler.transform(df2[numerical_cols])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASELINE LOGISTIC REGRESSION MODEL\n",
    "The purpose of using a Logistic Regression model in the context of predicting customer churn is to determine the probability that a customer will churn (leave the service) or not, based on the given features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the features and the target\n",
    "X = df2.drop('churn', axis=1)\n",
    "y = df2['churn']\n",
    "\n",
    "#splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#fitting the regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Making predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\\n\", recall)\n",
    "print(\"Precision:\\n\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model may be struggling to detect positive cases effectively, as indicated by the low recall. This could be a sign of imbalanced data, where the number of negative cases far exceeds the number of positive cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "#confusion Matrix Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Reds\", cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that the logistic regresion model is able to correctl classify a large number og negative instances but struggles to correctly identigy negative instances. This might be due to class imbalnces or other issues related to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC CURVE\n",
    "Plotting the ROC curve helps visualize the model's performance across different classification thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Get the predicted probabilities\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve and AUC score\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curve is above the diagonal line, indicating that the model perform better than random guessing. However the curve is not perfectly straight indicating that the model is able to discriminate between positive and negative instances to some extent. The AUC value of 0.82 suggests a good overall performance. The curve indicates that the logistic regression model is reasonably a good classifier for customer churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRECISION-RECALL CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, lw=2, color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HYPERPRAMETER TUNING USING GRIDSEARCHCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the best parameters\n",
    "print(\"Best Hyperparameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Displaying the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The evaluation results indicate the following about the model's performance:\n",
    "\n",
    "Accuracy (0.864): This means that about 86.4% of the predictions made by the model are correct. However, accuracy alone can be misleading, especially if the classes are imbalanced.\n",
    "\n",
    "Precision (0.639): The precision score indicates that when the model predicts the positive class, it is correct 63.9% of the time. This suggests that there are still some false positives in the model's predictions.\n",
    "\n",
    "Recall (0.228): The recall score is quite low, at 22.8%. This implies that the model is not capturing a large portion of the actual positive cases, resulting in many false negatives.\n",
    "\n",
    "F1-score (0.336): The F1-score, which balances precision and recall, is relatively low. This further indicates that the model is struggling to achieve a good balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the decision tree model\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#fitting the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metrics for the Decision Tree model indicate the following:\n",
    "\n",
    "Accuracy (0.9805): The model correctly classified 98.05% of the samples in the test set. This indicates a high overall performance.\n",
    "\n",
    "Precision (1.0000): The model achieved a perfect precision score, meaning all instances predicted as positive were indeed positive. There were no false positives.\n",
    "\n",
    "Recall (0.8713): The recall score of 87.13% indicates that out of all actual positive cases, the model correctly identified 87.13%. There were some false negatives (13), meaning the model missed a few positive cases.\n",
    "\n",
    "F1-score (0.9312): This score combines precision and recall into a single metric. A value of 0.9312 suggests a good balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VISULAIZING THE CONFUSION MATRIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEXCAYAAACqIS9uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYJklEQVR4nO3de3TMd/7H8dfkKhGErsRlK6VR6t5SlKSKVZcNSaiK/lC1i1LXLq24LFVKZa0W21W9UBpxJ6iDoFiE9nS1S9n+qipal0TkJolIMjO/P7qdX7OkKc1k0nyej3Oc0+93MvN5z6hnvvnO17DY7Xa7AADGcHP1AACAskX4AcAwhB8ADEP4AcAwhB8ADEP4AcAwhB/litVq1YoVK9S3b1+Fh4erV69eiomJUX5+/i96zFGjRql79+764IMP7vj+J0+e1Lhx4+56/f/WpUsXtWrVSjk5OUX2b9myRY0aNdKuXbt+8v7Xr1/XkCFDir09PDxcWVlZpTIrKiYPVw8A/NisWbOUmZmp999/X1WqVFFubq4mTZqkadOmKSYm5q4eMzk5WYcPH9Znn30md3f3O75/8+bNtXjx4rtauzjVq1dXQkKCIiIiHPu2bNmi3/zmNyXeNzMzUydPniz29vj4+NIYERUYR/woN7799ltt375dr776qqpUqSJJ8vX11csvv6xu3bpJ+v5od9KkSQoLC1Pv3r21YMECFRYWSvo+0EuWLFFUVJS6dOmilStXKjs7W3/84x9VWFiovn376sKFC2rUqJHS0tIc6/6wnZOTo3Hjxik8PFyRkZGaPn26bDabjh8/rrCwsLtavzh9+vTRtm3bHNsXL15Ubm6uGjRo4Ni3ceNG9e/fXxEREercubPWrFkjSYqOjlZeXp7Cw8NltVrVrFkzjR8/Xt27d9fJkycdz2fp0qUaMGCArFarrl69qpCQEB07dqwUfqfwa0f4UW6cPn1awcHB8vPzK7K/Zs2aeuKJJyRJc+bMkb+/v7Zv365Nmzbpyy+/1HvvvSdJys/PV/Xq1bV27VotXrxYCxculKenp5YvX65KlSopPj5e9erVK3b9hIQE5eTkKD4+Xhs3bpT0/TejH7vT9W/evHnbtTp16qQzZ84oJSVF0vdH6T8++s/JydGGDRu0fPlybd26VYsWLXL8xDNv3jzH83F3d1dBQYE6d+6s3bt3q3nz5o7HGDVqlDw9PfXuu+9q8uTJGjRokNq3b1/i7wMqPsKPcsPNzU02m+0nv+bQoUMaNGiQLBaLvLy8FBUVpUOHDjlu79q1qySpadOmys/PV25u7s9ev3Xr1jp79qwGDx6s5cuX65lnnlFQUJBT1vf09FSPHj20Y8cOSdLOnTsdP1VIUuXKlbVs2TIdPHhQr7/+upYtW/aTz6VNmza37HN3d1dMTIzefvttWSwWjRw58me/FqjYCD/KjRYtWujcuXPKzs4usj85OVkjRoxQXl7eLd8YbDab41SLJHl7e0uSLBaLJKmkj6L68ZvG9957rxISEjRixAhlZ2fr2WefveWN1tJcPyIiQtu2bdM///lPNWjQQP7+/o7brly5ooiICF28eFGtW7fWhAkTfvJ5+Pr63nb/pUuX5O3traSkJN7whQPhR7kRGBio3r17a+rUqY74Z2dna9asWfL391elSpUUEhKi2NhY2e125efna/369erQocMdrVOjRg3Hm6MJCQmO/WvWrFF0dLRCQkI0efJkhYSE6Kuvvipy39JY/wctW7ZUXl6eFi1apMjIyCK3nTp1SjVq1NDo0aMVGhqqjz76SNL3Vyh5eHjIarWW+E0tKytLkydP1muvvaawsDBNmzbtruZExUP4Ua7MnDlTwcHBioqKUnh4uPr376/g4GDNmTNHkjR9+nSlpaWpd+/e6t27t+rXr6/nnnvujtaYPn26Zs+ercjISJ0+fVo1a9aU9P0RuNVqVa9evdS3b19lZ2ffctlkaaz/Y+Hh4frmm28UGhpaZH/Hjh0VGBioHj16KCIiQpcvX1aNGjWUlJSkmjVrqkmTJurZs6fS09N/8nk+/vjj6tixo8aMGaMLFy4oNjb2rmdFxWHhY5kBwCwc8QOAYQg/ABiG8AOAYQg/ABiG8AOAYX4VH9Lm89AYV48A3Fb6J0tdPQJQrErFFJ4jfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwjIerB0Dpmv9CpPr+7iGlZeVKkr46n6zBU1YoomsrTR72hLy9PHThcpr+OGO10jJz5OZmUfTwnvp9p+aq7OOl3Ye/0IsLN7v4WcA0hw4e0OLXFyo/P18PPNBIs155VX5+fq4eq8LiiL+Cad+ygYZEr1D7qPlqHzVfg6es0MNN6umvL/XXwEnvqE3/V3U2KUWzxvSWJI15urMea9NQXZ79qx55ap7ataiv/t1bu/hZwCRpaWn68/RoLXx9ibZ9uFt1f3uv3vjrX1w9VoXmtCP+r7/+Wrt379aVK1fk5uamgIAAhYaGqnnz5s5a0nhenh5q2ei3mjC4q+pP/Y3OfZuqF/+ySQN7PaL3tybqwuU0SdKct3aqRrXKkqSnw9oqetEW5d0skCQNnPSO8gutLnsOME/i0cNq1qy5goLukyQ9FTVQT/UN19QZM2WxWFw7XAXllCP+2NhYvfDCC5Kk5s2bq2nTppKkGTNm6L333nPGkpBUu2Y1HfjkfzVjyTa1GzBfH//rG61fNEIN7wuQh4eb1i8aoePrpuj1KU8pO/emJKlhvQA92KCWdi4bq4/XRWt4/1ClZea4+JnAJFcuX1FgrVqO7cDAWsrOzlZODv8fOotTjvhXrVqlrVu3ysfHp8j+Z599VpGRkRo2bJgzljVe0qVrihz7d8f2olX7NGV4D13LyFGvx5qr18jFSknL1qsTIvTmjIF66oW35enhrrbN6yti7N/l5emuTW88p9FRnbR0zQHXPREYxW633Xa/mxtnop3FKa+sh4eHCgsLb9mfl5cnT09PZywJSc0a1tHA3z9SZJ/FYpGbxaK9iWeUfO267Ha7VsUnqm2L+pKky6mZ2rD7U+UXFCo796Y2J5xQu//cBpSFWrVrK/XqVcd2SkqyqlatJl9fXxdOVbE55Yj/ueeeU0REhB599FHVrFlTknT16lUdO3ZMEydOdMaSkGSz2bXwxf46euKcki5d04j+oTr11UUtXfOR5k2M1Gvv7FZaZo7Cu7bSp19ckCRt2XtCA3s9op2HTsnd3aKejzXVgeP/6+JnApM82iFEC2NeU1LSeQUF3acN69bq8S5dXT1WhWax2+12ZzxwcnKyEhMTlZKSIrvdrsDAQD366KMKDAy848fyeWiMEyasmKJ6PaJJz3aTu5ubLqZkaNTLsfr2SrqG9w/RyKcek5ubRRcup2nUy2t0+WqmKnl7au74cHVu10ge7u7ad+zfmhSzUVbr7X/8RlHpnyx19QgVwj8OHdTiRQtVUFig395bT3NffU3V/P1dPdavXqViDu2dFv7SRPhRXhF+lGfFhZ93TwDAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMB7F3TBnzpyfvOP06dNLfRgAgPMVG35/f/8yHAMAUFaKDf+YMWOKvVNubq5ThgEAOF+x4f/B3r17tXjxYuXm5sput8tmsykjI0MnTpwoi/kAAKWsxPAvWLBAEyZMUFxcnIYPH669e/eqcuXKZTEbAMAJSryqx8fHR7169VKrVq3k7e2tWbNm6dixY2UxGwDACUoMv5eXl/Lz81WvXj2dOXNGbm5uys/PL4vZAABOUOKpnq5du2rEiBGaP3++oqKi9Omnn3LFDwD8ilnsdru9pC+6dOmS6tSpo9OnT+uTTz5RWFiY7rnnnrKYT5Lk81DxVxgBrpT+yVJXjwAUq1Ixh/YlHvF/8cUXkqT09HRJUps2bXTlypUyDT8AoPSUGP6xY8c6/rugoECpqalq2rSpNm7c6NTBAADOUWL49+/fX2T7s88+I/oA8Ct2xx/S1qpVK8fpHwDAr8/PPscvSXa7XadOnVJeXp5ThwIAOM8dneO3WCy65557NGvWLGfOBABwohIv57xy5Ypq1apVZN/Zs2cVHBzs1MF+LPtmiVecAi5xKf2Gq0cAivVALd/b7i/2HH9GRoYyMjI0YsQIZWZmKiMjQ5mZmUpNTdXo0aOdNigAwLmKPdXzpz/9SUeOHJEktWvXzrHf3d1d3bp1c/5kAACnKPFUT3R0tObNm1dW89wWp3pQXnGqB+XZHZ/q+cH48eMdb+aeO3dOo0ePVmpqaqkOBwAoOyWGf8qUKWrQoIEkqW7dumrbtq2io6OdPhgAwDlKDH96erqGDBkiSfL29tbQoUN19epVpw8GAHCOEsNvtVqVnJzs2E5NTdXP+EBPAEA5VeJf4Bo6dKgiIiIUGhoqSUpMTNSLL77o9MEAAM7xsz6P/9///reOHTsmd3d3ZWZm6uDBg9qwYUNZzCeJq3pQfnFVD8qz4q7qKfGIX5Jq166tmzdvas2aNcrNzdXgwYNLdTgAQNn5yfCfO3dOK1eu1Pbt21W3bl3l5eVp//79qlKlSlnNBwAoZcW+uTt8+HANGjRIXl5eWrVqlXbs2KHKlSsTfQD4lSs2/GfOnFGTJk3UsGFD3XfffZK+/3ROAMCvW7HhP3DggPr166cdO3YoJCRE48aN082bN8tyNgCAExQbfg8PD/Xs2VOrV6/Wpk2bFBAQoLy8PD3xxBOKi4sryxkBAKXoZ13O+YMbN25o27ZtWrt2rbZs2eLMuYrgck6UV1zOifKsuMs57yj8rkL4UV4RfpRnd/3pnACAioXwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGMbD1QPAuex2u2bNiNb9wQ01ZOgfdP36db0yc5rOf/ONbHabwvpEaOiw4a4eEwZKPLRfa1Ysk8XNIj+/qhr74p8VUKuO3np9vk59/qkkqXX7EA0bNVEWi8XF01YshL8C++bc15o/d7ZOnvxc9wc3lCT9/W9vKCCwlhb8dbFu5Oaqf98wPdy6jVq0fMjF08IkN2/maeHcaVr87jrV+W09bV3/gZYvXqCOj3fTxW+TtGTFBtntNk0ePVRHDuxVSOdurh65QiH8Fdj6tbHqE9FXtWrXduyb/NI0Wa1WSVJq6lXl5xfIz6+Kq0aEoWxWm+x2KTcnW5KUdyNXnl5estmsysu7oYKCfNltdhUWFsjLy8vF01Y8hL8Ce2nqnyVJHx9PdOyzWCzy8PDQ9OjJ2pewW527/E5B99V31YgwlI+vr55/YaomPz9UVatWk81m02tLVyiwdl0dObBXQ/t1l81qVatH2qttx06uHrfCccqbu5cuXfrJX3C9OfNitO9QojKzMvX2sr+5ehwY5vzXX2ntqrf15vub9P7mBPUf9AfN+/Mkxa1cpqrVqmv11n1asXGXsrOytGXdKlePW+E45Yh/5MiROn/+vAICAmS324vcZrFYtG/fPmcsi5/h6JF/qGHDB1QzIFC+vpXVvefvtT9hj6vHgmH++UmiHmzWUrXr3itJ+n3kAL37t4Wy2WwaOe4leXp6ytPTU1169NaRg3sVOWCIiyeuWJwS/ri4OD399NOaOXOmWrdu7YwlcJf27tmlj/YlaOqMl1VQUKC9u3ep3aMdXD0WDHP/A4314Za1Sk+7puo17tGxwx8psHZd3d+wsQ5/tEctHn5EhYUF+vjIQTVu0tzV41Y4Tgm/n5+f5syZow0bNhD+cmbin17Sq3NmaUDfPpJFerzL7zTwfziaQtlq+XBb9Y16RlPHD5eHp4eqVKmmaXMXqXqNe/TWG6/pucGRcnNzU8uH26rf00NdPW6FY7H/97mYcij7ZrkfEYa6lH7D1SMAxXqglu9t9/M3dwHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxD+AHAMIQfAAxjsdvtdlcPAQAoOxzxA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCD8AGIbwA4BhCL9Btm/frl69eqlbt26KjY119ThAEdnZ2QoLC9N3333n6lEqPMJviOTkZC1atEhr1qxRfHy81q1bp7Nnz7p6LECS9Pnnn2vgwIE6f/68q0cxAuE3xNGjR9W+fXv5+/vL19dX3bt3165du1w9FiBJWr9+vWbOnKmAgABXj2IED1cPgLKRkpKimjVrOrYDAgL0r3/9y4UTAf9v7ty5rh7BKBzxG+J2H8JqsVhcMAkAVyP8hggMDFRqaqpjOyUlhR+rAUMRfkN06NBBiYmJSktL040bN7Rnzx499thjrh4LgAtwjt8QgYGBmjhxooYMGaKCggI9+eSTatGihavHAuAC/AtcAGAYTvUAgGEIPwAYhvADgGEIPwAYhvADgGEIPyq07777Tg8++KDCw8Mdv/r06aONGzf+oscdOXKkNm/eLEkKDw9XVlZWsV97/fp1DRky5I7X2LVrlwYPHnzXMwLF4Tp+VHiVKlVSfHy8Yzs5OVlhYWFq1qyZGjdu/Isf/8ePfTuZmZk6efLkL14HKC2EH8YJDAxUUFCQjhw5otmzZ+vGjRvy8/PT6tWrtWHDBsXFxclms8nf318zZszQ/fffr+TkZE2ZMkUpKSmqU6eOrl275ni8Ro0aKTExUTVq1NBbb72lLVu2yMPDQ0FBQZo/f76io6OVl5en8PBwbd68WefPn9fcuXOVkZEhq9WqwYMH68knn5QkvfHGG9q+fbv8/f0VFBTkqpcIFRzhh3FOnDihCxcuKC8vT2fPntX+/fvl5+enjz/+WFu3blVsbKx8fHx0+PBhjR07Vjt37tTs2bPVsmVLTZgwQUlJSYqIiLjlcfft26fNmzdr/fr1qlatmubNm6cPPvhA8+bNU+/evRUfH6/CwkKNGzdOCxYsUNOmTXX9+nUNGDBAwcHBSk1N1Z49e7R161ZVqlRJzz//fNm/ODAC4UeF98PRtiRZrVZVr15dMTExunbtmho1aiQ/Pz9J0oEDB5SUlKSoqCjHfTMzM5WRkaGjR4/qpZdekiQFBQWpXbt2t6yTmJioHj16qFq1apKk6OhoSSryL0qdP39eFy5c0NSpU4vMd/r0aX399dfq1q2bY55+/fpp9erVpflSAJIIPwzw3+f4f7B582b5+vo6tm02m8LDwzV58mTHdkpKiqpVqyaLxVLko609PG79o+Pu7l7ko66zsrJuedPXarWqatWqReZJTU1VlSpVFBMTU2QNd3f3u3i2QMm4qgf4j44dO+rDDz9USkqKJCkuLk7PPPOMJCk0NFTr1q2TJF26dEnHjx+/5f4dOnRQQkKCsrOzJUlLlizRypUr5eHhIavVKrvdrvr168vb29sR/suXLyssLEynTp1SaGiodu3apaysLNlsthLfNAbuFkf8wH+EhoZq+PDhGjZsmCwWi/z8/LR06VJZLBbNnDlT0dHR6tmzp2rVqnXbq4E6deqks2fPauDAgZKk4OBgvfLKK/Lx8VGTJk3Us2dPxcXF6c0339TcuXP1zjvvqLCwUOPHj1fr1q0lSV9++aX69eunqlWrqnHjxkpPTy/T1wBm4NM5AcAwnOoBAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwDOEHAMMQfgAwzP8Br72Dkkd6acUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix:\n",
    "\n",
    "True Negatives (566): The number of negative instances correctly classified.\n",
    "False Positives (0): No instances were incorrectly classified as positive.\n",
    "False Negatives (13): Instances that were actually positive but predicted as negative.\n",
    "True Positives (88): Positive instances correctly classified by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HYPERPARAMETER TUNING THE MODEL WITH GRIDSEARCHCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Decision Tree Model: DecisionTreeClassifier(max_depth=20, random_state=42)\n",
      "Accuracy: 0.9805097451274363\n",
      "Precision: 1.0\n",
      "Recall: 0.8712871287128713\n",
      "F1-score: 0.9312169312169313\n",
      "Confusion Matrix:\n",
      " [[566   0]\n",
      " [ 13  88]]\n"
     ]
    }
   ],
   "source": [
    "# Defining the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6]\n",
    "}\n",
    "\n",
    "# Using GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=clf, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring='accuracy', \n",
    "                           cv=5, \n",
    "                           n_jobs=-1, \n",
    "                           verbose=1)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#getting the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Decision Tree Model:\", best_model)\n",
    "\n",
    "# Evaluating the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "#evaluating the model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metrics of the model remain the same after the tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9235382308845578\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      1.00      0.96       566\n",
      "        True       1.00      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.92       667\n",
      "   macro avg       0.96      0.75      0.81       667\n",
      "weighted avg       0.93      0.92      0.91       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train random forest model\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Summary**\n",
    "\n",
    "The model performs well in predicting non-churning customers, with high precision, recall, and F1-score.\n",
    "However, it struggles to identify churning customers, with a recall of only 0.50. This means that half of the actual churning customers are missed by the model.\n",
    "To improve the model, techniques such as adjusting class weights, using a different threshold for classification, or employing resampling methods (e.g., SMOTE) could help address the imbalance and improve the recall for the \"True\" class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improving the Random forest model by adjusting class weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Balanced Class Weights Accuracy: 0.9145427286356822\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      1.00      0.95       566\n",
      "        True       1.00      0.44      0.61       101\n",
      "\n",
      "    accuracy                           0.91       667\n",
      "   macro avg       0.95      0.72      0.78       667\n",
      "weighted avg       0.92      0.91      0.90       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training random forest with balanced class weights\n",
    "random_forest_balanced = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "random_forest_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred_rf_balanced = random_forest_balanced.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Random Forest with Balanced Class Weights Accuracy:\", accuracy_score(y_test, y_pred_rf_balanced))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_balanced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is very effective at identifying non-churning customers, but its ability to detect churning customers remains limited, even after adjusting the class weights. Further steps, such as more advanced resampling techniques, tuning the decision threshold, or using more sophisticated models, may be needed to improve churn detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling the Minority Class (SMOTE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with SMOTE Accuracy: 0.9325337331334332\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      1.00      0.96       566\n",
      "        True       0.97      0.57      0.72       101\n",
      "\n",
      "    accuracy                           0.93       667\n",
      "   macro avg       0.95      0.79      0.84       667\n",
      "weighted avg       0.93      0.93      0.93       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train random forest on SMOTE data\n",
    "random_forest_smote = RandomForestClassifier(random_state=42)\n",
    "random_forest_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf_smote = random_forest_smote.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest with SMOTE Accuracy:\", accuracy_score(y_test, y_pred_rf_smote))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_smote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of SMOTE has enhanced the model's ability to detect churning customers, as seen in the improved recall for the \"True\" class. The model maintains strong performance for non-churning customers while boosting the detection of churn cases. However, further tuning may still be needed to increase the recall for the \"True\" class to catch more at-risk customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
